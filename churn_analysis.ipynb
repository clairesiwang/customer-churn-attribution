{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7266997d",
   "metadata": {},
   "source": [
    "\n",
    "# Customer Churn Attribution — Reproducible Notebook\n",
    "\n",
    "This notebook loads the four datasets, computes simple monthly features, and applies the **risk scoring** logic from the report.\n",
    "\n",
    "> Folder layout expected:\n",
    ">\n",
    "> ```\n",
    "> customer-churn-attribution/\n",
    "> ├── data/\n",
    "> │   ├── subscriptions.csv\n",
    "> │   ├── feature_usage.csv\n",
    "> │   ├── support_tickets.csv\n",
    "> │   ├── churn_events.csv\n",
    "> │   └── accounts.csv\n",
    "> └── notebooks/\n",
    ">     └── churn_analysis.ipynb\n",
    "> ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc8946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Pretty display options\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "print(\"✅ Libraries ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc55adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Load datasets (graceful if files are not present)\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "\n",
    "def safe_read_csv(path):\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        print(f\"Loaded: {path.name}  shape={df.shape}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⚠️  Not found: {path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "subs = safe_read_csv(DATA_DIR / \"subscriptions.csv\")\n",
    "usage = safe_read_csv(DATA_DIR / \"feature_usage.csv\")\n",
    "tickets = safe_read_csv(DATA_DIR / \"support_tickets.csv\")\n",
    "churn  = safe_read_csv(DATA_DIR / \"churn_events.csv\")\n",
    "accounts = safe_read_csv(DATA_DIR / \"accounts.csv\")\n",
    "\n",
    "display(subs.head(3))\n",
    "display(usage.head(3))\n",
    "display(tickets.head(3))\n",
    "display(churn.head(3))\n",
    "display(accounts.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc1171f",
   "metadata": {},
   "source": [
    "\n",
    "## Feature Engineering (monthly panel)\n",
    "\n",
    "This section demonstrates the *deployment-ready* features used in the report:\n",
    "- `usage_days_m`: distinct active days in a month\n",
    "- `is_downgrade`: downgrade flag from subscriptions\n",
    "- `ttr_p50_m`: median ticket response time (hours)\n",
    "- `csat_m`: mean CSAT in month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f6f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Basic feature engineering (example skeleton)\n",
    "# NOTE: This is a lightweight example; adapt to your real schemas as needed.\n",
    "\n",
    "# --- usage_days_m ---\n",
    "usage_feat = pd.DataFrame()\n",
    "if not usage.empty:\n",
    "    # Expect columns like: account_id, date (YYYY-MM-DD), maybe feature_name\n",
    "    use = usage.copy()\n",
    "    # Ensure date type\n",
    "    if \"date\" in use.columns:\n",
    "        use[\"date\"] = pd.to_datetime(use[\"date\"])\n",
    "        use[\"month\"] = use[\"date\"].dt.to_period(\"M\").dt.to_timestamp()\n",
    "        usage_feat = (\n",
    "            use.groupby([\"account_id\", \"month\"])[\"date\"]\n",
    "              .nunique()\n",
    "              .rename(\"usage_days_m\")\n",
    "              .reset_index()\n",
    "        )\n",
    "    else:\n",
    "        print(\"⚠️  'feature_usage.csv' missing 'date' column; please add or adapt.\")\n",
    "\n",
    "# --- is_downgrade ---\n",
    "downgrade_feat = pd.DataFrame()\n",
    "if not subs.empty:\n",
    "    # Expect columns: account_id, month_start, is_downgrade (0/1), mrr\n",
    "    s = subs.copy()\n",
    "    # Try to coerce month_start\n",
    "    for col in [\"month\", \"month_start\", \"period_start\"]:\n",
    "        if col in s.columns:\n",
    "            s[col] = pd.to_datetime(s[col]).dt.to_period(\"M\").dt.to_timestamp()\n",
    "            s = s.rename(columns={col: \"month\"})\n",
    "            break\n",
    "    if \"month\" not in s.columns:\n",
    "        print(\"⚠️  'subscriptions.csv' missing a month column; please add 'month' or 'month_start'.\")\n",
    "    downgrade_feat = s.groupby([\"account_id\",\"month\"], as_index=False).agg({\n",
    "        \"is_downgrade\":\"max\",  # if any downgrade happened in month\n",
    "        \"mrr\":\"max\"            # keep one MRR value\n",
    "    })\n",
    "\n",
    "# --- tickets: ttr_p50_m & csat_m ---\n",
    "tickets_feat = pd.DataFrame()\n",
    "if not tickets.empty:\n",
    "    # Expect columns: account_id, created_at, ttr_hours, csat\n",
    "    t = tickets.copy()\n",
    "    # Coerce time\n",
    "    for col in [\"created_at\", \"created\", \"timestamp\"]:\n",
    "        if col in t.columns:\n",
    "            t[col] = pd.to_datetime(t[col])\n",
    "            t[\"month\"] = t[col].dt.to_period(\"M\").dt.to_timestamp()\n",
    "            break\n",
    "    if \"month\" not in t.columns:\n",
    "        print(\"⚠️  'support_tickets.csv' missing a timestamp column; please add 'created_at'.\")\n",
    "    # Standardize column names if present\n",
    "    if \"ttr_hours\" not in t.columns:\n",
    "        # Try alternate names\n",
    "        for alt in [\"ttr\", \"response_hours\", \"response_time_hours\"]:\n",
    "            if alt in t.columns:\n",
    "                t = t.rename(columns={alt: \"ttr_hours\"})\n",
    "                break\n",
    "    if \"csat\" not in t.columns:\n",
    "        for alt in [\"csat_score\", \"customer_satisfaction\"]:\n",
    "            if alt in t.columns:\n",
    "                t = t.rename(columns={alt: \"csat\"})\n",
    "                break\n",
    "    tickets_feat = t.groupby([\"account_id\",\"month\"], as_index=False).agg(\n",
    "        ttr_p50_m = (\"ttr_hours\",\"median\"),\n",
    "        csat_m    = (\"csat\",\"mean\")\n",
    "    )\n",
    "\n",
    "# Merge monthly panel\n",
    "monthly = None\n",
    "to_merge = [df for df in [usage_feat, downgrade_feat, tickets_feat] if not df.empty]\n",
    "if to_merge:\n",
    "    from functools import reduce\n",
    "    monthly = reduce(lambda l,r: pd.merge(l, r, on=[\"account_id\",\"month\"], how=\"outer\"), to_merge)\n",
    "    # Fill missing with safe defaults\n",
    "    for col, val in [(\"usage_days_m\", 0), (\"is_downgrade\", 0), (\"ttr_p50_m\", np.nan), (\"csat_m\", np.nan), (\"mrr\", np.nan)]:\n",
    "        if col in monthly.columns:\n",
    "            monthly[col] = monthly[col].fillna(val)\n",
    "    print(\"✅ Built monthly feature table:\", monthly.shape)\n",
    "    display(monthly.head(10))\n",
    "else:\n",
    "    print(\"⚠️  Could not build monthly features; please check your input files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c79975",
   "metadata": {},
   "source": [
    "\n",
    "## Risk Scoring (from the report)\n",
    "\n",
    "High-level rule set:\n",
    "\n",
    "```\n",
    "if usage_days_m < 6:\n",
    "    if is_downgrade == 1 or ttr_p50_m > 48 or csat_m < 3.5:\n",
    "        risk_score = 'High'\n",
    "    else:\n",
    "        risk_score = 'Medium'\n",
    "else:\n",
    "    risk_score = 'Low'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba8b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Risk scoring implementation\n",
    "def apply_risk_score(df):\n",
    "    def score_row(row):\n",
    "        usage_days = row.get(\"usage_days_m\", 0)\n",
    "        downgrade  = row.get(\"is_downgrade\", 0)\n",
    "        ttr        = row.get(\"ttr_p50_m\", np.nan)\n",
    "        csat       = row.get(\"csat_m\", np.nan)\n",
    "\n",
    "        if usage_days < 6:\n",
    "            if (downgrade == 1) or (pd.notnull(ttr) and ttr > 48) or (pd.notnull(csat) and csat < 3.5):\n",
    "                return \"High\"\n",
    "            return \"Medium\"\n",
    "        return \"Low\"\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"risk_score\"] = out.apply(score_row, axis=1)\n",
    "    return out\n",
    "\n",
    "scored = None\n",
    "if monthly is not None:\n",
    "    scored = apply_risk_score(monthly)\n",
    "    print(\"✅ Risk scoring complete:\", scored.shape)\n",
    "    display(scored.head(10))\n",
    "else:\n",
    "    print(\"⚠️  Monthly features not available; skipping scoring.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8108f8a7",
   "metadata": {},
   "source": [
    "\n",
    "## Export Deliverables\n",
    "\n",
    "- `high_risk_accounts.csv`: all Medium/High risk accounts with key metrics  \n",
    "- `high_risk_top20.csv`: top 20 high-risk accounts ranked by `MRR × Risk Level`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cecfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) Export deliverables (files will be written next to this notebook by default)\n",
    "if scored is not None and not scored.empty:\n",
    "    # Keep key columns\n",
    "    keep_cols = [c for c in [\"account_id\",\"month\",\"mrr\",\"usage_days_m\",\"is_downgrade\",\"ttr_p50_m\",\"csat_m\",\"risk_score\"] if c in scored.columns]\n",
    "    export = scored[keep_cols].copy()\n",
    "\n",
    "    # Medium/High set\n",
    "    mask_mh = export[\"risk_score\"].isin([\"Medium\",\"High\"])\n",
    "    mh = export[mask_mh].sort_values([\"risk_score\",\"mrr\"], ascending=[True, False])\n",
    "    mh.to_csv(\"high_risk_accounts.csv\", index=False)\n",
    "    print(\"✅ Wrote: high_risk_accounts.csv  rows=\", len(mh))\n",
    "\n",
    "    # Top-20 by MRR × Risk Level (High > Medium > Low)\n",
    "    risk_rank = {\"High\": 2, \"Medium\": 1, \"Low\": 0}\n",
    "    export[\"risk_weight\"] = export[\"risk_score\"].map(risk_rank).fillna(0)\n",
    "    export[\"priority\"] = export[\"mrr\"].fillna(0) * (1 + export[\"risk_weight\"])\n",
    "    top20 = export.sort_values([\"priority\"], ascending=False).head(20)\n",
    "    top20.to_csv(\"high_risk_top20.csv\", index=False)\n",
    "    print(\"✅ Wrote: high_risk_top20.csv  rows=\", len(top20))\n",
    "\n",
    "    display(top20.head(10))\n",
    "else:\n",
    "    print(\"⚠️  Nothing to export; ensure input CSVs are present and monthly features are computed.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
